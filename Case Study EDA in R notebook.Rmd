---
title: "Case Study: Exploratory Data Analysis in R"
subtitle: Datacamp course
output: html_notebook
---

### Chapter 1 - Data cleaning and summarizing with dplyr

##### Filtering Rows

The vote column in the dataset has a number that represents that country's vote:

* 1 = Yes
* 2 = Abstain
* 3 = No
* 8 = Not present
* 9 = Not a member

One step of data cleaning is removing observations (rows) that you're not interested in. In this case, you want to remove "Not present" and "Not a member".

* Load the dplyr package.  
* Print the votes table.  
* Filter out rows where the vote recorded is "not present" or "not a member", leaving cases where it is "yes", "abstain", or "no".

```{r Exercise 1-1}
#####
# Load data from web if needed
# votes <- readRDS(gzcon(url("https://assets.datacamp.com/production/repositories/420/datasets/ddfa750d993c73026f621376f3c187f276bf0e2a/votes.rds")))

#descriptions <- readRDS(gzcon(url"https://assets.datacamp.com/production/repositories/420/datasets/a438432333a31a6f4aba2d5507df9a44e513b518/descriptions.rds"))

#####
# Load the dplyr package
library(dplyr)

# Print the votes dataset
head(votes) ### head() used to save space

# Filter for votes that are "yes", "abstain", or "no"
votes %>% filter(vote <= 3) %>% 
   head() ### head() used to save space

```

***

##### Adding a year column

The next step of data cleaning is manipulating your variables (columns) to make them more informative.

In this case, you have a session column that is hard to interpret intuitively. But since the UN started voting in 1946, and holds one session per year, you can get the year of a UN resolution by adding 1945 to the session number.  

* Use mutate() to add a year column by adding 1945 to the session column.

```{r Exercise 1-2}

# Add another %>% step to add a year column
votes %>%
   filter(vote <= 3) %>%
   mutate(year = session + 1945) %>%
   head() ###


```

***

##### Adding a country column

The country codes in the ccode column are what's called [Correlates of War codes](https://correlatesofwar.org/data-sets/cow-country-codes). This isn't ideal for an analysis, since you'd like to work with recognizable country names.

You can use the countrycode package to translate. For example:

> library(countrycode)  
   #Translate the country code 2  
      countrycode(2, "cown", "country.name")  
[1] "United States"  
   #Translate multiple country codes  
      countrycode(c(2, 20, 40), "cown", "country.name")  
[1] "United States" "Canada"        "Cuba"

* Load the countrycode package.
* Convert the country code 100 to its country name.
* Add a new country column in your mutate() statement containing country names, using the countrycode() function to translate from the ccode column. Save the result to votes_processed.


```{r Exercise 1-3}
# Load the countrycode package
library(countrycode)

# Convert country code 100
countrycode(100, "cown", "country.name")

# Add a country column within the mutate: votes_processed
votes_processed <- votes %>%
   filter(vote <= 3) %>%
   mutate(year = session + 1945, country = countrycode(ccode, "cown", "country.name"))

```

***

##### Summarizing the full dataset

In this analysis, you're going to focus on "% of votes that are yes" as a metric for the "agreeableness" of countries.  

You'll start by finding this summary for the entire dataset: the fraction of all votes in their history that were "yes". Note that within your call to summarize(), you can use n() to find the total number of votes and mean(vote == 1) to find the fraction of "yes" votes.

* Print the votes_processed dataset that you created in the previous exercise.
* Summarize the dataset using the summarize() function to create two columns:
   + total: with the number of votes
   + percent_yes: the percentage of "yes" votes

```{r Exercise 1-4}
# Print votes_processed
votes_processed %>% head() ###

# Find total and fraction of "yes" votes
votes_processed %>%
   summarize(total = n(), percent_yes = mean(vote == 1))

```

***

##### Summarizing by year

The summarize() function is especially useful because it can be used within groups.

For example, you might like to know how much the average "agreeableness" of countries changed from year to year. To examine this, you can use group_by() to perform your summary not for the entire dataset, but within each year.

* Add a group_by() to your code to summarize() within each year.

```{r Exercise 1-5}
# Change this code to summarize by year
votes_processed %>%
   group_by(year) %>%
   summarize(total = n(), percent_yes = mean(vote == 1))

```

***

##### Summarizing by country

In the last exercise, you performed a summary of the votes within each year. You could instead summarize() within each country, which would let you compare voting patterns between countries.

* Change the code in the editor to summarize() within each country rather than within each year. Save the result as by_country.

```{r Exercise 1-6}
# Summarize by country: by_country
by_country <- votes_processed %>%
   group_by(country) %>%
   summarize(total = n(), percent_yes = mean(vote == 1))

```

***

##### Sorting by percentage of "yes" votes

Now that you've summarized the dataset by country, you can start examining it and answering interesting questions.

For example, you might be especially interested in the countries that voted "yes" least often, or the ones that voted "yes" most often.


* Print the by_country dataset created in the last exercise.
* Use arrange() to sort the countries in ascending order of percent_yes.
* Arrange the countries by the same variable, but in descending order.


```{r Exercise 1-7}
# You have the votes summarized by country
by_country <- votes_processed %>%
   group_by(country) %>%
   summarize(total = n(), percent_yes = mean(vote == 1))

# Print the by_country dataset
by_country %>% head() ###

# Sort in ascending order of percent_yes
arrange(by_country, percent_yes) %>% head() ###

# Now sort in descending order
arrange(by_country, desc(percent_yes)) %>% head() ###

```

***

##### Filtering summarized output

In the last exercise, you may have noticed that the country that voted least frequently, Zanzibar, had only 2 votes in the entire dataset. You certainly can't make any substantial conclusions based on that data!

Typically in a progressive analysis, when you find that a few of your observations have very little data while others have plenty, you set some threshold to filter them out.

* Use filter() to remove from the sorted data countries that have fewer than 100 votes.

```{r Exercise 1-8}
# Filter out countries with fewer than 100 votes
by_country %>% 
   arrange(percent_yes) %>%
   filter(total >= 100) %>% head() ###

```

***

### Chapter 2 - Data visualization with ggplot2

##### Plotting a line over time

In the last chapter, you learned how to summarize() the votes dataset by year, particularly the percentage of votes in each year that were "yes".

You'll now use the ggplot2 package to turn your results into a visualization of the percentage of "yes" votes over time.

The by_year dataset has the number of votes and percentage of "yes" votes each year.
* Load the ggplot2 package.
* Use ggplot() with the geom_line layer to create a line plot with year on the x-axis and percent_yes on the y-axis.

```{r Exercise 2-1}
# Define by_year
by_year <- votes_processed %>%
   group_by(year) %>%
   summarize(total = n(), percent_yes = mean(vote == 1))

# Load the ggplot2 package
library(ggplot2)

# Create line plot
ggplot(by_year, aes(x = year, y = percent_yes)) + geom_line()

```

***

##### Other ggplot2 layers

A line plot is one way to display this data. You could also choose to display it as a scatter plot, with each year represented as a single point. This requires changing the layer (i.e. geom_line() to geom_point()).

You can also add additional layers to your graph, such as a smoothing curve with geom_smooth(). 

Change the plot to a scatter plot and add a smoothing curve.

```{r Exercise 2-2}
# Change to scatter plot and add smoothing curve
ggplot(by_year, aes(x = year, y = percent_yes)) +
   geom_point() + geom_smooth()
  
```

***

##### Summarizing by year and country

You're more interested in trends of voting within specific countries than you are in the overall trend. So instead of summarizing just by year, summarize by both year and country, constructing a dataset that shows what fraction of the time each country votes "yes" in each year.

Change the code in the editor to group by both year and country rather than just by year. Save the result as by_year_country.

```{r Exercise 2-3}
# Group by year and country: by_year_country
by_year_country <- votes_processed %>%
  group_by(year, country) %>%
  summarize(total = n(),
            percent_yes = mean(vote == 1))

```

***

##### Plotting just the UK over time

Now that you have the percentage of time that each country voted "yes" within each year, you can plot the trend for a particular country. In this case, you'll look at the trend for just the United Kingdom.

This will involve using filter() on your data before giving it to ggplot2.


* Print the by_year_country dataset.
* Create a filtered version of the dataset called UK_by_year.
* Create a line plot of the percentage of "yes" votes over time for the United Kingdom.



```{r Exercise 2-4}
# Start with by_year_country dataset
by_year_country <- votes_processed %>%
   group_by(year, country) %>%
   summarize(total = n(), percent_yes = mean(vote == 1))

# Print by_year_country
by_year_country %>% head()

# Create a filtered version: UK_by_year
UK_by_year <- by_year_country %>% 
   filter(country == "United Kingdom")

# Line plot of percent_yes over time for UK only
ggplot(UK_by_year, aes(x = year, y = percent_yes)) + geom_line()

```

***

##### Plotting multiple countries

Plotting just one country at a time is interesting, but you really want to compare trends between countries. For example, suppose you want to compare voting trends for the United States, the UK, France, and India.

You'll have to filter to include all four of these countries and use another aesthetic (not just x- and y-axes) to distinguish the countries on the resulting visualization. Instead, you'll use the color aesthetic to represent different countries.

The by_year_country dataset you created in the last exercise is available in your workspace.

* Create a filtered version of by_year_country called filtered_4_countries with just the countries listed in the editor (you may find the %in% operator useful here).
* Show the trend for each of these countries on the same graph, using color to distinguish each country.

```{r Exercise 2-5}
# Vector of four countries to examine
countries <- c("United States", "United Kingdom",
               "France", "India")

# Filter by_year_country: filtered_4_countries
filtered_4_countries <- by_year_country %>%
   filter(country %in% countries)

# Line plot of % yes in four countries
ggplot(filtered_4_countries, 
       aes(x = year, y = percent_yes, color = country)) + geom_line()

```

***

##### Faceting the time series

Now you'll take a look at six countries. While in the previous exercise you used color to represent distinct countries, this gets a little too crowded with six.

Instead, you will facet, giving each country its own sub-plot. To do so, you add a facet_wrap() step after all of your layers.


* Create a filtered version that contains these six countries called filtered_6_countries.
* Use the filtered dataset (containing summarized data for six countries) to create a plot with one facet for each country.


```{r Exercise 2-6}
# Vector of six countries to examine
countries <- c("United States", "United Kingdom",
               "France", "Japan", "Brazil", "India")

# Filtered by_year_country: filtered_6_countries
filtered_6_countries <- by_year_country %>% 
   filter(country %in% countries)

# Line plot of % yes over time faceted by country
ggplot(filtered_6_countries, aes(x = year, y = percent_yes, color = country)) +
   geom_line() + facet_wrap(~ country)

```

***

##### Faceting with free y-axis

In the previous plot, all six graphs had the same axis limits. This made the changes over time hard to examine for plots with relatively little change.

Instead, you may want to let the plot choose a different y-axis for each facet.


Change the faceted plot so that the y-axis is freely chosen for each facet, rather than being the same for all six.

```{r Exercise 2-7}
# Line plot of % yes over time faceted by country
ggplot(filtered_6_countries, aes(year, percent_yes)) +
  geom_line() +
  facet_wrap(~ country, scales = "free_y")

```

***

##### Choose your own countries

The purpose of an exploratory data analysis is to ask questions and answer them with data. Now it's your turn to ask the questions.

You'll choose some countries whose history you are interested in and add them to the graph. If you want to look up the full list of countries, enter by_country$country in the console.

Add three more countries to the countries vector and therefore to the faceted graph.

```{r Exercise 2-8}
# Add three more countries to this list
countries <- c("United States", "United Kingdom",
               "France", "Japan", "Brazil", "India", 
               "Spain", "Portugal", "Chad") ### new countries

# Filtered by_year_country: filtered_countries
filtered_countries <- by_year_country %>%
   filter(country %in% countries)

# Line plot of % yes over time faceted by country
ggplot(filtered_countries, aes(year, percent_yes)) +
   geom_line() + facet_wrap(~ country, scales = "free_y")

```

***

### Chapter 3 - Tidy modeling with broom


##### Linear regression on the United States

A linear regression is a model that lets us examine how one variable changes with respect to another by fitting a best fit line. It is done with the lm() function in R.

Here, you'll fit a linear regression to just the percentage of "yes" votes from the United States.


* Print the US_by_year data to the console.
* Using just the US data in US_by_year, use lm() to run a linear regression predicting percent_yes from year. Save this to a variable US_fit.
* Summarize US_fit using the summary() function.

```{r Exercise 3-1}
# Percentage of yes votes from the US by year: US_by_year
US_by_year <- by_year_country %>%
   filter(country == "United States")

# Print the US_by_year data
US_by_year

# Perform a linear regression of percent_yes by year: US_fit
US_fit <- lm(percent_yes ~ year, data = US_by_year)

# Perform summary() on the US_fit object
summary(US_fit)

```

***

##### Tidying a linear regression model
In the last section, you fit a linear model. Now, you'll use the tidy() function in the broom package to turn that model into a tidy data frame.

The US_fit linear model is available in your workspace.

* Load the broom package.
* Use the tidy() function from broom on the model object to turn it into a tidy data frame. Don't store the result; just print the output to the console.

```{r Exercise 3-2}
# Load the broom package
library(broom)

# Call the tidy() function on the US_fit object
tidy(US_fit)

```

***

##### Combining models for multiple countries

One important advantage of changing models to tidied data frames is that they can be combined.

In an earlier section, you fit a linear model to the percentage of "yes" votes for each year in the United States. Now you'll fit the same model for the United Kingdom and combine the results from both countries.


* Fit a model for the United Kingdom similar to the one you fit for the US and save it as UK_fit.
* Tidy US_fit into a data frame called US_tidied and the UK model into UK_tidied.
* Use bind_rows() from dplyr to combine the two tidied models, printing the result to the console.

```{r Exercise 3-3}
# Linear regression of percent_yes by year for US
US_by_year <- by_year_country %>%
  filter(country == "United States")

US_fit <- lm(percent_yes ~ year, US_by_year)

# Fit model for the United Kingdom
UK_by_year <- by_year_country %>%
    filter(country == "United Kingdom")

UK_fit <- lm(percent_yes ~ year, data = UK_by_year)

# Create US_tidied and UK_tidied
US_tidied = tidy(US_fit)
UK_tidied = tidy(UK_fit)

# Combine the two tidied models
bind_rows(US_tidied, UK_tidied)

```

***

##### Nesting a data frame

Right now, the by_year_country data frame has one row per country-vote pair. So that you can model each country individually, you're going to "nest" all columns besides country, which will result in a data frame with one row per country. The data for each individual country will then be stored in a list column called data.


* Load the tidyr package.
* Use the nest() function to nest all the columns in by_year_country except country.

```{r Exercise 3-4}
# Load the tidyr package
library(tidyr)
# Nest all columns besides country
by_year_country %>% nest(-country) %>% head() ###

```

***

##### List columns
This "nested" data has an interesting structure. The second column, data, is a list, a type of R object that hasn't yet come up in this course that allows complicated objects to be stored within each row. This is because each item of the data column is itself a data frame.

You can use nested$data to access this list column and double brackets to access a particular element.
For example, nested$data[[1]] would give you the data frame with Afghanistan's voting history (the percent_yes per year), since Afghanistan is the first row of the table.

Print the data frame from the data column that contains the data for Brazil.

```{r Exercise 3-5}
# All countries are nested besides country
nested <- by_year_country %>% nest(-country)

# Print the nested data for Brazil
nested$data[[7]]

```

***

##### Unnesting

The opposite of the nest() operation is the unnest() operation. This takes each of the data frames in the list column and brings those rows back to the main data frame.

In this exercise, you are just undoing the nest() operation. In the next section, you'll learn how to fit a model in between these nesting and unnesting steps that makes this process useful.

Unnest the data list column, so that the table again has one row for each country-year pair, much like by_year_country.

```{r Exercise 3-6}
# All countries are nested besides country
nested <- by_year_country %>% nest(-country)

# Unnest the data column to return it to its original form
nested %>% unnest(data) %>% head() ###

```

***

##### Performing linear regression on each nested dataset

Now that you've divided the data for each country into a separate dataset in the data column, you need to fit a linear model to each of these datasets.

The map() function from purrr works by applying a formula to each item in a list, where . represents the individual item. For example, you could add one to each of a list of numbers:

> map(numbers, ~ 1 + .)

This means that to fit a model to each dataset, you can do:

> map(data, ~ lm(percent_yes ~ year, data = .))

where . represents each individual item from the data column in by_year_country. Recall that each item in the data column is a dataset that pertains to a specific country.

* Load the tidyr and purrr packages.
* After nesting, use the map() function within a mutate() to perform a linear regression on each dataset (i.e. each item in the data column in by_year_country) modeling percent_yes as a function of year. Save the results to the model column.

```{r Exercise 3-7}
# Load tidyr and purrr
library(tidyr)
library(purrr)

# Perform a linear regression on each item in the data column
by_year_country %>% 
   nest(-country) %>%
   mutate(model = map(data, ~ lm(percent_yes ~ year, data = .)))

```

***

##### Tidy each linear regression model

You've now performed a linear regression on each nested dataset and have a linear model stored in the list column model. But you can't recombine the models until you've tidied each into a table of coefficients. To do that, you'll need to use map() one more time and the tidy() function from the broom package.

Recall that you can simply give a function to map() (e.g. map(models, tidy)) in order to apply that function to each item of a list.

* Load the broom package. #done previously
* Use the map() function to apply the tidy() function to each linear model in the model column, creating a new column called tidied.

```{r Exercise 3-8}
# Add another mutate that applies tidy() to each model
by_year_country %>%
  nest(-country) %>%
  mutate(model = map(data, ~ lm(percent_yes ~ year, data = .))) %>%
  mutate(tidied = map(model, tidy))

```

***

##### Unnesting a data frame
You now have a tidied version of each model stored in the tidied column. You want to combine all of those into a large data frame, similar to how you combined the US and UK tidied models earlier. Recall that the unnest() function from tidyr achieves this.

* Add an unnest() step to unnest the tidied models stored in the tidied column. Save the result as country_coefficients.
* Print the resulting country_coefficients object to the console.

```{r Exercise 3-9}
# Add one more step that unnests the tidied column
country_coefficients <- by_year_country %>%
   nest(-country) %>%
   mutate(model = map(data, ~ lm(percent_yes ~ year, data = .)),
          tidied = map(model, tidy)) %>%
            unnest(tidied)


# Print the resulting country_coefficients variable
head(country_coefficients) ###

```

***

##### Filtering model terms

You currently have both the intercept and slope terms for each by-country model. You're probably more interested in how each is changing over time, so you want to focus on the slope terms.

* Print the country_coefficients data frame to the console.
* Perform a filter() step that extracts only the slope (not intercept) terms.

```{r Exercise 3-10}

# Print the country_coefficients dataset
country_coefficients %>% head()

# Filter for only the slope terms
country_coefficients %>% 
   filter(term == "year")

```

***

##### Filtering for significant countries

Not all slopes are significant, and you can use the p-value to guess which are and which are not.

However, when you have lots of p-values, like one for each country, you run into the problem of multiple hypothesis testing, where you have to set a stricter threshold. The p.adjust() function is a simple way to correct for this, where p.adjust(p.value) on a vector of p-values returns a set that you can trust.

Here you'll add two steps to process the slope_terms dataset: use a mutate to create the new, adjusted p-value column, and filter to filter for those below a .05 threshold.


Use the p.adjust() function to adjust the p.value column, saving the result into a new p.adjusted column. Then, filter for cases where p.adjusted is less than .05.

```{r Exercise 3-11}
# Filter for only the slope terms
slope_terms <- country_coefficients %>%
  filter(term == "year")

# Add p.adjusted column, then filter

slope_terms %>%
   mutate(p.adjusted = p.adjust(p.value)) %>%
   filter(p.adjusted < 0.05)

```


***

##### Sorting by slope

Now that you've filtered for countries where the trend is probably not due to chance, you may be interested in countries whose percentage of "yes" votes is changing most quickly over time. Thus, you want to find the countries with the highest and lowest slopes; that is, the estimate column.

* Using arrange() and desc(), sort the filtered countries to find the countries whose percentage "yes" is most quickly increasing over time.
* Using arrange(), sort to find the countries whose percentage "yes" is most quickly decreasing.

```{r Exercise 3-12}
# Filter by adjusted p-values
filtered_countries <- country_coefficients %>%
   filter(term == "year") %>%
   mutate(p.adjusted = p.adjust(p.value)) %>%
   filter(p.adjusted < 0.05)

# Sort for the countries increasing most quickly
filtered_countries %>%
   arrange(estimate)

# Sort for the countries decreasing most quickly
filtered_countries %>%
   arrange(desc(estimate))

```

***

### Chatper 4 - Joining and tidying

##### Joining datasets with inner_join

In the first chapter, you created the votes_processed dataset, containing information about each country's votes. You'll now combine that with the new descriptions dataset, which includes topic information about each country, so that you can analyze votes within particular topics.

To do this, you'll make use of the inner_join() function from dplyr.

* Load the dplyr package.
* Print the votes_processed dataset.
* Print the new descriptions dataset.
* Join the two datasets using dplyr's inner_join(), using the rcid and session columns to match them. Save as votes_joined.

```{r Exercise 4-1}

# Load dplyr package
# library(dplyr) ### uncomment if needed again

# Print the votes_processed dataset
votes_processed %>% head() ###

# Print the descriptions dataset
descriptions %>% head() ###

# Join them together based on the "rcid" and "session" columns
votes_joined <- votes_processed %>%
   inner_join(descriptions, by = c("rcid","session"))

```

***

##### Filtering the joined dataset

There are six columns in the descriptions dataset (and therefore in the new joined dataset) that describe the topic of a resolution:

1. me: Israeli-Palestinian conflict
2. nu: Nuclear weapons and nuclear material
3. di: Arms control and disarmament
4. hr: Human rights
5. co: Colonialism
6. ec: Economic development
Each contains a 1 if the resolution is related to this topic and a 0 otherwise.

Filter the votes_joined dataset for votes relating to colonialism.

```{r Exercise 4-2}
# Filter for votes related to colonialism
votes_joined %>% filter(co == 1) %>% head() ###

```

***

##### Visualizing colonialism votes

In an earlier exercise, you graphed the percentage of votes each year where the US voted "yes". Now you'll create that same graph, but only for votes related to colonialism.

* Load the ggplot2 package.
* Filter the votes_joined dataset for only votes by the United States relating to colonialism, then summarize() the percentage of votes that are "yes" within each year. Name the resulting column percent_yes and save the entire data frame as US_co_by_year.
* Add a geom_line() layer to your ggplot() call to create a line graph of the percentage of "yes" votes on colonialism (percent_yes) cast by the US over time.

```{r Exercise 4-3}
# Load the ggplot2 package
# library(ggplot2) ### uncomment if needed

# Filter, then summarize by year: US_co_by_year
US_co_by_year <- votes_joined %>%
   filter(country == "United States", co == 1) %>%
   group_by(year) %>%
   summarize(percent_yes = mean(vote == 1))

# Graph the % of "yes" votes over time
ggplot(US_co_by_year, aes(x = year, y = percent_yes)) + 
   geom_line()

```

***

##### Using gather to tidy a dataset

In order to represent the joined vote-topic data in a tidy form so we can analyze and graph by topic, we need to transform the data so that each row has one combination of country-vote-topic. This will change the data from having six columns (me, nu, di, hr, co, ec) to having two columns (topic and has_topic).

* Load the tidyr package.
* Gather the six topic columns in votes_joined into one column called topic (containing one of me, nu, etc.) and a column called has_topic (containing 0 or 1). Print the result without saving it.
* You don't actually care about the cases where has_topic is 0. Perform the gather() operation again, but this time also filter for only the rows where the topic in topic describes the vote. Save the result as votes_gathered.

```{r Exercise 4-4}
# Load the tidyr package
# library(tidyr) ### uncoment if needed

# Gather the six me/nu/di/hr/co/ec columns
votes_joined %>% 
   gather(topic, has_topic, me:ec) %>% head() ###


# Perform gather again, then filter
votes_gathered <- votes_joined %>%
   gather(topic, has_topic, me:ec) %>%
   filter(has_topic == 1)

```

***

##### Recoding the topics

There's one more step of data cleaning to make this more interpretable. Right now, topics are represented by two-letter codes:

1. me: Israeli-Palestinian conflict
2. nu: Nuclear weapons and nuclear material
3. di: Arms control and disarmament
4. hr: Human rights
5. co: Colonialism
6. ec: Economic development

So that you can interpret the data more easily, recode the data to replace these codes with their full name. You can do that with dplyr's recode() function, which replaces values with ones you specify:

> example <- c("apple", "banana", "apple", "orange")
recode(example, apple = "plum", banana = "grape")

Use the recode() function from dplyr in a mutate() to replace each two-letter code in the votes_gathered data frame with the corresponding full name. Save this as votes_tidied.

```{r Exercise 4-5}
# Replace the two-letter codes in topic: votes_tidied
votes_tidied <- votes_gathered %>%
   mutate(topic = recode(topic,
      me = "Israeli-Palestinian conflict",
      nu = "Nuclear weapons and nuclear material",
      di = "Arms control and disarmament",
      hr = "Human rights",
      co = "Colonialism", 
      ec = "Economic development"))

```

***

##### Summarize by country, year, and topic

In previous exercises, you summarized the votes dataset by country, by year, and by country-year combination.

Now that you have topic as an additional variable, you can summarize the votes for each combination of country, year, and topic (e.g. for the United States in 2013 on the topic of nuclear weapons.)

* Print the votes_tidied dataset to the console.
* In a single summarize() call, compute both the total number of votes (total) and the percentage of "yes" votes (percent_yes) for each combination of country, year, and topic. Save this as by_country_year_topic. Make sure that you ungroup() after summarizing.
* Print the by_country_year_topic dataset to the console.

```{r Exercise 4-6}
# Print votes_tidied
votes_tidied %>% head() ###

# Summarize the percentage "yes" per country-year-topic
by_country_year_topic <- votes_tidied %>%
   group_by(country, year, topic) %>%
   summarize(total = sum(n()), percent_yes = mean(vote == 1)) %>%
   ungroup()

# Print by_country_year_topic
by_country_year_topic %>% head() ###

```

***

##### Visualizing trends in topics for one country

You can now visualize the trends in percentage "yes" over time for all six topics side-by-side. Here, you'll visualize them just for the United States.

* Load the ggplot2 package.
* Filter the by_country_year_topic dataset for just the United States and save the result as US_by_country_year_topic.
* Use this dataset to graph the percentage "yes" over time for the United States, faceting by topic.

```{r Exercise 4-7}
# Load the ggplot2 package
# library(ggplot2) ### uncomment if needed

# Filter by_country_year_topic for just the US
US_by_country_year_topic <- by_country_year_topic %>%
   filter(country == "United States")

# Plot % yes over time for the US, faceting by topic
ggplot(US_by_country_year_topic, aes(x = year, y = percent_yes)) + 
   geom_line() + facet_wrap(~ topic)

```

***

##### Nesting by topic and country

In the last chapter, you constructed a linear model for each country by nesting the data in each country, fitting a model to each dataset, then tidying each model with broom and unnesting the coefficients. The code looked something like this:

>country_coefficients <- by_year_country %>%
  nest(-country) %>%
  mutate(model = map(data, ~ lm(percent_yes ~ year, data = .)),
         tidied = map(model, tidy)) %>%
  unnest(tidied)
  
Now, you'll again be modeling change in "percentage" yes over time, but instead of fitting one model for each country, you'll fit one for each combination of country and topic.

* Load the purrr, tidyr, and broom packages.
* Print the by_country_year_topic dataset to the console.
* Fit a linear model within each country and topic in this dataset, saving the result as country_topic_coefficients. You can use the above code as a starting point.
* Print the country_topic_coefficients dataset to the console.

```{r Exercise 4-8}
# Load purrr, tidyr, and broom
# library(purrr) # library(tidyr) # library(broom) ### uncommment if needed

# Print by_country_year_topic
by_country_year_topic %>% head() ###

# Fit model on the by_country_year_topic dataset
country_topic_coefficients <- by_country_year_topic %>%
        nest(-country,-topic) %>%
        mutate(model = map(data, ~ lm(percent_yes ~ year, data = .))
        , tidied = map(model, tidy)) %>%
        unnest(tidied)

# Print country_topic_coefficients
country_topic_coefficients %>% head()

```

***

##### Interpreting tidy models
Now you have both the slope and intercept terms for each model. Just as you did in the last chapter with the tidied coefficients, you'll need to filter for only the slope terms.

You'll also have to extract only cases that are statistically significant, which means adjusting the p-value for the number of models, and then filtering to include only significant changes.

* Filter the country_topic_coefficients data to include only the slope term.
* Add a p.adjusted column containing adjusted p-values (using the p.adjust() function).
* Filter for only adjusted p-values less than .05.
* Save the result as country_topic_filtered.

```{r Exercise 4-9}
# Create country_topic_filtered
country_topic_filtered <- country_topic_coefficients %>%
        filter(term == "year") %>%
        mutate(p.adjusted = p.adjust(p.value)) %>%
        filter(p.adjusted < 0.05)

```

***

##### Steepest trends by topic
country_topic_filtered from the previous exercise is available in your workspace. Which combination of country and topic has the steepest downward trend?

```{r Exercise 4-10}
### multiple choice question
country_topic_filtered %>% 
   arrange(estimate) %>% head(1)
```

***

##### Checking models visually

In the last exercise, you found that over its history, Vanuatu (an island nation in the Pacific Ocean) sharply changed its pattern of voting on the topic of Israeli-Palestinian conflict.

Let's examine this country's voting patterns more closely. Recall that the by_country_year_topic dataset contained one row for each combination of country, year, and topic. You can use that to create a plot of Vanuatu's voting, faceted by topic.

```{r Exercise 4-11}
# Create vanuatu_by_country_year_topic
vanuatu_by_country_year_topic <- by_country_year_topic %>%
   filter(country == "Vanuatu")

# Plot of percentage "yes" over time, faceted by topic
ggplot(vanuatu_by_country_year_topic, 
       aes(x = year, y = percent_yes)) +
         geom_line() + facet_wrap(~topic)

```

***